using Random, Distributions, Interpolations, Base.Iterators, FastGaussQuadrature, BenchmarkTools, Optim, LogExpFunctions, Plots, CSV, DataFrames, DataFramesMeta, ForwardDiff, LinearAlgebra, Roots, QuadGK, Statistics, ThreadsX

const ZÌ„ = 1.9599639845401

# fold the unit-square parameter space across a+b=1
fold(a,b) = a+b>1 ? (1-b,1-a) : (a,b)

@inline diffcdf(N,a,b) = cdf(N,b) - cdf(N,a)

import Base.rand, Distributions.pdf, Distributions.logpdf, Distributions.cdf, Distributions.logcdf, Distributions.ccdf, Distributions.logccdf, Statistics.quantile

# type to represent distribution of maximum of m normal draws, Float64 only
struct MaxNormal <: Distribution{Univariate, Continuous}
	m::Float64  # number of draws over which to take max
	invm::Float64
	Î¼::Float64  # mean
	Ïƒ::Float64  # sd
	ğ’©::Normal{Float64}
	MaxNormal(m=1., Î¼=0., Ïƒ=1.) = new(m,1/m,Î¼,Ïƒ,Normal(Î¼,Ïƒ))
end
cdf(s::MaxNormal, x::Float64) = cdf(s.ğ’©,x) ^ s.m
logccdf(s::MaxNormal, x::Float64) = log1mexp(s.m * logcdf(s.ğ’©,x))
ccdf(s::MaxNormal, x::Float64) = exp(logccdf(s,x))
pdf(s::MaxNormal, x::Float64) = pdf(s.ğ’©,x) * s.m * cdf(s.ğ’©,x)^(s.m-1)
logpdf(s::MaxNormal, x::Float64) = logpdf(s.ğ’©,x) + log(s.m) + (s.m-1) * logcdf(s.ğ’©,x)
quantile(s::MaxNormal, x::Float64) = quantile(s.ğ’©, x^s.invm)
rand(rng::AbstractRNG, s::MaxNormal) = quantile(s.ğ’©, rand(rng)^s.invm)

struct MinNormal <: Distribution{Univariate, Continuous}
	m::Float64  # number of draws over which to take max
	invm::Float64
	Î¼::Float64  # mean
	Ïƒ::Float64  # sd
	ğ’©::Normal{Float64}
	MinNormal(m=1., Î¼=0., Ïƒ=1.) = new(m,1/m,Î¼,Ïƒ,Normal(Î¼,Ïƒ))
end
cdf(s::MinNormal, x::Float64) = exp(logcdf(s,x))
logcdf(s::MinNormal, x::Float64) = log1mexp(s.m * logccdf(s.ğ’©,x))
ccdf(s::MinNormal, x::Float64) = ccdf(s.ğ’©,x) ^ s.m
pdf(s::MinNormal, x::Float64) = pdf(s.ğ’©,x) * s.m * ccdf(s.ğ’©,x)^(s.m-1)
logpdf(s::MinNormal, x::Float64) = logpdf(s.ğ’©,x) + log(s.m) + (s.m-1) * logccdf(s.ğ’©,x)
quantile(s::MinNormal, x::Float64) = cquantile(s.ğ’©, (1-x)^s.invm)
rand(rng::AbstractRNG, s::MinNormal) = cquantile(s.ğ’©, rand(rng)^s.invm)

# to parameterize an n-vector of probabilities summing to 1 with an unbounded (n-1)-vector, apply logistic transform to latter, then map to squared spherical coordinates
# https://en.wikipedia.org/wiki/N-sphere#Spherical_coordinates, https://math.stackexchange.com/questions/2861449/parameterizations-of-the-unit-simplex-in-mathbbr3
function Râ¿toSimplex(q::Vector{T}) where T
	_q = logistic.(q)
	p = Vector{T}(undef, length(q)+1)
	Î sinÂ² = one(T)
	for i âˆˆ eachindex(_q)
		cosÂ² = cospi(_q[i])^2
		p[i] = Î sinÂ² * cosÂ²
		Î sinÂ² *= one(T) - cosÂ²
	end
	p[end] = Î sinÂ²
	p
end
function SimplextoRâ¿(p::Vector{T}) where T
	q = Vector{T}(undef, length(p)-1)
	sum = p[end]
	for i âˆˆ reverse(eachindex(q))
		sum += p[i]
		q[i] = acos(âˆš(p[i] / sum)) / Ï€
	end
	q .= logit.(q)
end


function HnFl(z::T, p::Vector{T}, Î¼::Vector, Ï„::Vector{T}, pD::T, pF::T, u::T, m::T; truncate=true) where T<:Number
	pH = m * (1 - pD - pF)
	length(p) < length(Î¼) && (p = [p; 1-sum(p)])
	ğ’©  = Normal()
	ğ’©Î¼ = @. Normal(Î¼, âˆš(1 + Ï„^2))
	ğ’©Ï‰ = @. NormalCanon(z + Î¼/Ï„^2, 1 + 1/Ï„^2)
	if abs(z) â‰¥ ZÌ„
		result = zero(T)
		@inbounds for (páµ¢,ğ’©Î¼áµ¢,ğ’©Ï‰áµ¢) âˆˆ zip(p,ğ’©Î¼,ğ’©Ï‰)
			if z < 0
				result += páµ¢ * pdf(ğ’©Î¼áµ¢, z) * (one(T) + pH * (1-u) * quadgk(Ï‰ -> (a = pdf(ğ’©Ï‰áµ¢,Ï‰)*(cdf(ğ’©,ZÌ„-Ï‰)-cdf(ğ’©,-ZÌ„-Ï‰)) * ccdf(ğ’©,z-Ï‰)^(m-1) / (1-ccdf(ğ’©, -ZÌ„-Ï‰)^m);
																																		 isnan(a) || isinf(a) ? 0. : a), 
																                               -Inf, Inf)[1])
			else
				result += páµ¢ * pdf(ğ’©Î¼áµ¢, z) * (one(T) + pH *    u  * quadgk(Ï‰ -> (a = pdf(ğ’©Ï‰áµ¢,Ï‰)*(cdf(ğ’©,ZÌ„-Ï‰)-cdf(ğ’©,-ZÌ„-Ï‰)) * cdf(ğ’©,z-Ï‰)^(m-1) / (1 - cdf(ğ’©,  ZÌ„-Ï‰)^m);
																																		 isnan(a) || isinf(a) ? 0. : a), 
																                               -Inf, Inf)[1])
			end
		end
	else
		result = pD * dot(p, pdf.(ğ’©Î¼, z))
	end
	truncate && (result /= (1 - pF * dot(p, (cdf.(ğ’©Î¼,ZÌ„) - cdf.(ğ’©Î¼,-ZÌ„)))))
	result
end

# object to hold pre-computed stuff for log likelihood computation
struct HnFstuff
	D::Int  # number of mixture components
	z::Vector{Float64}  # all data
	zC::Vector{Float64}  # just the central, insignificant z's
	N::Int; NC::Int; NL::Int; NU::Int  # number of z's, insigficant z's, lower significant z's, upper
	knots::LinRange  # interpolation knots in [ZÌ„,max]
	spline::Interpolations.InterpolationType  # type of interpolation
	zSint::NTuple{2,Vector{Float64}}  # lower- & upper-tail significant z values mapped to cardinal knot numbering space since interpolate() is faster with cardinally spaced knots
	X::Vector{Float64}; W::Vector{Float64}  # quadrature nodes & weights
	lnW::Vector{Float64}
end
# constructor
function HnFstuff(z::Vector{Float64}; D::Int, interpres::Int, quadnodes::Int)
	zC = z[abs.(z) .< ZÌ„]

	s = ZÌ„ - 3/interpres; e = maximum(z)+.1
	knots = s : 1/interpres : e  # LinRange(s, e, ceil(Int, (e - s) * interpres) + 1)
	zSint = (-z[z .â‰¤ -ZÌ„] .- s) .* interpres .+ 1, (z[z .â‰¥ ZÌ„] .- s) .* interpres .+ 1  # map tail z values to knot numbering 1, 2, ... for ZÌ„-3/interpres, ZÌ„-2/interpres, ...
	
	X, W = gausshermite(quadnodes)
	W ./= âˆšÏ€
	
	HnFstuff(D, z, zC, length(z), length(zC), length.(zSint)..., knots, BSpline(Quadratic(Free(OnGrid()))), zSint, X, W, log.(W))
end

# bulk log probabilities as function of data & parameters, for estimation
function HnFll(o::HnFstuff, p::Vector{T}, Î¼::Vector, Ï„::Vector{T}, pD::T, pF::T, u::T, m::T) where T<:Number
	Ï„ = exp.(Ï„)
	m = exp(m); mm1 = m - one(T)
	u = logistic(u)
	p = Râ¿toSimplex(p)
	pD, pF, _pH = Râ¿toSimplex([pD,pF])
	pH = m * _pH * [one(T)-u u]

	LC = fill(zero(T), o.NC)  # likelihood for insignificant obs
	LS = fill(zero(T), o.NL), fill(zero(T), o.NU)  # for significant obs, left & right tails

	ğ’©  = Normal()
	ğ’©Î¼ = Normal.(Î¼, .âˆš(1 .+ Ï„.^2))

	for (páµ¢,Î¼áµ¢,Ï„áµ¢,ğ’©Î¼áµ¢) âˆˆ zip(p,Î¼,Ï„,ğ’©Î¼)
		ÏƒÂ² = Ï„áµ¢^2; ÏƒÂ² /= one(T)+ÏƒÂ²; Ïƒ = âˆšÏƒÂ²

		# math on integration and interpolation points, outside loops
		X  = o.X * (âˆš2 * Ïƒ)
		XU =  ZÌ„ .- X
		XL = -ZÌ„ .- X
		ğ’©X = Normal.(X)

		buf = Vector{T}(undef, length(o.knots))  # pre-allocating this hampers automatic differentiation since type changes

		# lower tail
		k1 = collect((Î¼áµ¢/Ï„áµ¢^2 .- o.knots) .* -ÏƒÂ²)  #    -(z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points
		k2 = collect(k1 - o.knots  )               # z - (z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points
		fill!(buf, zero(T))
		@inbounds Threads.@threads for j âˆˆ eachindex(o.knots)
			k1j, k2j = k1[j], k2[j]
			for (ğ’©x,xl,xu,lnw) âˆˆ zip(ğ’©X,XL,XU,o.lnW)  # quadrature integration
				buf[j] += exp(lnw + logdiffcdf(ğ’©, k1j + xu, k1j + xl) + mm1 * logccdf(ğ’©x, k2j) - log1mexp(m * logccdf(ğ’©, k1j + xl)))
			end
		end
		buf .= páµ¢ .* pdf.(ğ’©Î¼áµ¢, -o.knots) .* (one(T) .+ pH[1] .* buf)
		LS[1] .+= interpolate!(buf, o.spline).(o.zSint[1])  # likelihoods for significant observations

		# upper tail
		k1 .= collect((Î¼áµ¢/Ï„áµ¢^2 .+ o.knots) .* -ÏƒÂ²)  #    -(z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points
		k2 .= collect(k1 + o.knots               )  # z - (z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points
		fill!(buf, zero(T))
		@inbounds Threads.@threads for j âˆˆ eachindex(o.knots)
			k1j, k2j = k1[j], k2[j]
			for (ğ’©x,xl,xu,lnw) âˆˆ zip(ğ’©X,XL,XU,o.lnW)  # quadrature integration
				buf[j] += exp(lnw + logdiffcdf(ğ’©, k1j + xu, k1j + xl) + mm1 * logcdf(ğ’©x, k2j) - log1mexp(m * logcdf(ğ’©, k1j + xu)))
			end
		end
		buf .= páµ¢ .* pdf.(ğ’©Î¼áµ¢, o.knots) .* (one(T) .+ pH[2] .* buf)
		LS[2] .+= interpolate!(buf, o.spline).(o.zSint[2])  # likelihoods for significant observations

		LC .+= (páµ¢ * pD) .* pdf.(ğ’©Î¼áµ¢, o.zC)  # likelihoods for center/insignificant observations
	end
	return(mapreduce(v->ThreadsX.mapreduce(log, +, v, init=zero(T)), +, (LC,LS...)) - xlog1py(o.N, -pF * dot(p, (cdf.(ğ’©Î¼,ZÌ„) - cdf.(ğ’©Î¼,-ZÌ„)))))
end

# log likelihood--function of parameters only
negHnFll(o)        = v -> -HnFll(o, v[1:o.D-1], v[o.D:2*o.D-1], v[2*o.D:3*o.D-1], v[3*o.D:end]...)
negHnFll0cent(o)   = v -> -HnFll(o, v[1:o.D-1], zeros(Float64,o.D), v[o.D:2*o.D-1], v[2*o.D:end]...)  # impose Î¼=0
negHnFllSharedÎ¼(o) = v -> -HnFll(o, v[1:o.D-1], fill(v[o.D],o.D), v[o.D+1:2*o.D], v[2*o.D+1:end]...) # impose shared Î¼

function HnFCDF(o::HnFstuff, z::T, p::Vector{T}, Î¼::Vector{T}, Ï„::Vector{T}, pD::T, pF::T, U) where T<:Number
	pH = 1 - pD - pF

	ğ’©H = Normal.(âˆš2Ï„ * o.X' .+ Î¼)
	ğ’©  = Normal.(Î¼, .âˆš(1 .+ Ï„.^2))

	a = cdf.(ğ’©H, -ZÌ„)
	b = ccdf.(ğ’©H, ZÌ„)
	if z â‰¤ ZÌ„  # tails
		result = pH * p'* cdf.(ğ’©, min(z,-ZÌ„)                          ) + pH * (p' * ( cdf.(ğ’©H, min(z,-ZÌ„))       .* (one(T) .- a .- b) ./ (a .+ U .* b)) * o.W)
	else
		result = pH * p'*(cdf.(ğ’©,       -ZÌ„) + cdf.(ğ’©,z) - cdf.(ğ’©,ZÌ„)) + pH * (p' * ((a + U * (cdf.(ğ’©H,z) - b)) .* (one(T) .- a .- b) ./ (a .+ U .* b)) * o.W)
	end
	z > -ZÌ„ &&  # central bit
		(result += pD * (p' * (cdf.(ğ’©, min(z,ZÌ„)) - cdf.(ğ’©,-ZÌ„))))
	result / (1 - pF * (p' * (cdf.(ğ’©,ZÌ„) - cdf.(ğ’©,-ZÌ„))))
end

# f(z|Ï‰)
function fZcondÎ©(z, Ï‰, pD, pF, u, m; truncate=true)
	pH = 1 - pD - pF
	result = abs(z) < ZÌ„ ? pD * pdf(Normal(Ï‰),z) :
	         pdf(Normal(Ï‰),z) + pH * exp(logdiffcdf(Normal(Ï‰),ZÌ„,-ZÌ„) + (z â‰¤ -ZÌ„ ? log1p(-u) + logpdf(MinNormal(m,Ï‰),z) -  logcdf(MinNormal(m,Ï‰),-ZÌ„) :
					                                                                    log(   u) + logpdf(MaxNormal(m,Ï‰),z) - logccdf(MaxNormal(m,Ï‰), ZÌ„)  ))
	truncate && (result /= (1 - pF *(cdf(Normal(Ï‰), ZÌ„) - cdf(Normal(Ï‰),-ZÌ„))))
	isnan(result) || isinf(result) ? 0. : result
end

# F(z|Ï‰)
function FZcondÎ©(z, Ï‰, pD, pF, u, m)
	pH = 1 - pD - pF
	l = 1 - u
	ğ’© = Normal(Ï‰)
	a = cdf(ğ’©,-ZÌ„)
	b = cdf(ğ’©, ZÌ„)
	if z > ZÌ„  # tails
		ğ’©max = MaxNormal(m,Ï‰)
		result = 1 - (u * pH * exp(logccdf(ğ’©max,z) - logccdf(ğ’©max,ZÌ„) + logdiffcdf(ğ’©, ZÌ„, -ZÌ„)) + ccdf(ğ’©,z)) / (1-pF*(b-a))
	else
		ğ’©min = MinNormal(m,Ï‰)
		if z < -ZÌ„
			result = l * pH * exp(logcdf(ğ’©min, z) - cdf(ğ’©min, -ZÌ„) + logdiffcdf(ğ’©, ZÌ„, -ZÌ„)) + cdf(ğ’©,z)
		else
			result = l * pH * b + (1 - l * pH - pD) * a + pD * cdf(ğ’©,z)
		end
		result /= 1-pF*(b-a)
	end
	result
end


# f(z), f(Ï‰), f(Ï‰|z), E[Ï‰|z]
fZ = HnFl
fÎ©(Ï‰, p, Î¼, Ï„) = p'pdf.(Normal.(Î¼,Ï„), Ï‰)
fÎ©condZ(Ï‰, z, p, Î¼, Ï„, pD, pF, u, m) = fZcondÎ©(z, Ï‰, pD, pF, u, m, truncate=false) * fÎ©(Ï‰, p, Î¼, Ï„) / fZ(z, p, Î¼, Ï„, pD, pF, u, m, truncate=false)
EÎ©condZ(z, p, Î¼, Ï„, pD, pF, u, m) = quadgk(Ï‰->Ï‰ * fÎ©condZ(Ï‰, z, p, Î¼, Ï„, pD, pF, u, m), -Inf, Inf)[1]

# CIs
Cquant(Î±, z, pD, pF, u, m) = find_zero(Ï‰ -> Î± - FZcondÎ©(z, Ï‰, pD, pF, u, m), (-20,20))
CI(Î±, z, pD, pF, u, m) = Cquant(Î±/2, z, pD, pF, u, m), Cquant(1-Î±/2, z, pD, pF, u, m)


function HnFDGP(N, p, Î¼, Ï„, pD, pF, u, m)
	p = vcat(p)
	Î¼ = vcat(Î¼)
	Ï„ = vcat(Ï„)
	length(p) < length(Î¼) && (p = [p; 1-sum(p)])
	pDF = pD + pF
	pDFu = pDF + (1 - pDF) * u

	I = rand(Categorical(p), N)
	Î© = map(i->rand(Normal(Î¼[i], Ï„[i])), I)
	Zâœ» = rand.(Normal.(Î©))
	Z = similar(Zâœ»)
	@inbounds Threads.@threads for i âˆˆ eachindex(Zâœ»)
		if abs(Zâœ»[i]) > ZÌ„
			Z[i] = Zâœ»[i]
		else
			r = rand()
			if r < pD
				Z[i] = Zâœ»[i]
			elseif r < pDF
				Z[i] = NaN
			elseif r < pDFu
				ğ’© = MaxNormal(m,Î©[i])
				Z[i] = quantile(ğ’©, rand(Uniform(cdf(ğ’©, ZÌ„), 1.)))
			else
				ğ’© = MinNormal(m,Î©[i])
				Z[i] = quantile(ğ’©, rand(Uniform(0., cdf(ğ’©, -ZÌ„))))
			end
		end
	end
	keep = .!isnan.(Z) .&& abs.(Z).<10
	(Î©=Î©[keep], Zâœ»=Zâœ»[keep], Z=Z[keep])
end


# confirm match between model and simulation
pD = .4
pF = .3
u = .8
p = [.7]
Î¼ = [-1.,1.]
Ï„ = [2.,2.]
m = 5.6

z = HnFDGP(3_000_000,p,Î¼,Ï„,pD,pF,u,m).Z

histogram(z, normalize=:pdf, legend=false)
zplot = -9:.1:9
plot!(zplot, map(z->.01+HnFl(z,p,Î¼,Ï„,pD,pF,u,m), zplot))
plot!(zplot, map(z->.02+exp(-negHnFll(HnFstuff([z], D=length(Î¼), interpres=300, quadnodes=25))(vcat(logit.(p),Î¼,log.(Ï„),logit(pD),logit(pF),logit(u),log(m)))),zplot))

o = HnFstuff(z, D=length(Î¼), interpres=300, quadnodes=25)
@time res = optimize(negHnFll(o), vcat(logit.(p),Î¼,log.(Ï„),logit(pD),logit(pF),logit(u),log(m)), LBFGS(), autodiff=:forward)
Î¸â‚‚ = Optim.minimizer(res)
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, uÌ‚, mÌ‚ = logistic.(Î¸â‚‚[1:o.D-1]), Î¸â‚‚[o.D:2*o.D-1], exp.(Î¸â‚‚[2*o.D:3*o.D-1]), logistic(Î¸â‚‚[3*o.D]), logistic(Î¸â‚‚[3*o.D+1]), logistic(Î¸â‚‚[3*o.D+2]), exp(Î¸â‚‚[3*o.D+3])
pÌ‚ = vcat(pÌ‚, 1-sum(pÌ‚))
pÌ‚D, pÌ‚F = fold(pÌ‚D, pÌ‚F)
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚D=pÌ‚D, pÌ‚F=pÌ‚F, uÌ‚=uÌ‚, mÌ‚=mÌ‚))

plot!(zplot, map(z->.03+HnFl(z, pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, uÌ‚, mÌ‚), zplot))


# data prep
df = DataFrame(CSV.File(raw"D:\OneDrive\Documents\Work\Clients & prospects\GiveWell\Noisy data\Georgescu.Wren.csv"))
@. df.cilevel[ismissing(df.cilevel) || df.cilevel==.0095 || df.cilevel==.05] = .95
@. df.z = log(df.mean) / (ifelse(ismissing(df.lower) || iszero(df.lower), log(df.upper / df.mean), log(df.upper / df.lower) / 2) / cquantile(Normal(), (1 - df.cilevel)/2.))
@. @subset!(df, !ismissing(:z) && !ismissing(:lower))
@. @subset!(df, iszero(:mistake) && abs(:z) < 10.)
@. @subset!(df, :source!="Abstract")
df.z = Float64.(df.z)
histogram(df.z, normalize=:pdf, label="Actual published effects", legend=:topleft)

# fit 2-component min/max model
p = Float64[.5,.5]
Î¼ = [0.,0.]
Ï„ = [1.,2.]
pD = .4
pF = .5
pH = 1 - pD - pF
u = .75
m = 3.

o = HnFstuff(df.z, D=length(Î¼), interpres=300, quadnodes=25)
@time res2 = optimize(negHnFll(o), vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),SimplextoRâ¿([pD,pF,pH])...,logit(u),log(m)), LBFGS(), autodiff=:forward)
Î¸, ll = Optim.minimizer(res2), Optim.minimum(res2)
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, pÌ‚H, uÌ‚, mÌ‚ = Râ¿toSimplex(Î¸[1:o.D-1]), Î¸[o.D:2*o.D-1], exp.(Î¸[2*o.D:3*o.D-1]), Râ¿toSimplex(Î¸[3*o.D:3*o.D+1])..., logistic(Î¸[3*o.D+2]), exp(Î¸[3*o.D+3])
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚D=pÌ‚D, pÌ‚F=pÌ‚F, pÌ‚H=pÌ‚H, uÌ‚=uÌ‚, mÌ‚=mÌ‚))
println("Mean Ï‰ = ", pÌ‚'Î¼Ì‚)
ses2 = sqrt.(diag(pinv(ForwardDiff.hessian(negHnFll(o), Î¸â‚‚))))

zplot = -10:.1:10
pplotfit = map(z->HnFl(z, pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, uÌ‚, mÌ‚), zplot)
plt = histogram(df.z, normalize=:pdf, label="Actual published estimates", legend=:topleft)
plot!(zplot, [pÌ‚[1] * pdf.(Normal(Î¼Ì‚[1],Ï„Ì‚[1]), zplot)+pÌ‚[2] * pdf.(Normal(Î¼Ì‚[2],Ï„Ì‚[2]), zplot) pÌ‚[1] * pdf.(Normal(Î¼Ì‚[1],âˆš(1+Ï„Ì‚[1]^2)), zplot)+pÌ‚[2] * pdf.(Normal(Î¼Ì‚[2],âˆš(1+Ï„Ì‚[2]^2)), zplot) pplotfit], label=["Model: true effects" "Model: initial estimates" "Model: published estimates"])
png(plt, "fit")
plt

# distribution of z | Ï‰=2
Ï‰=2; zplot=-3:.01:5; plot(zplot, mapreduce(z->fZcondÎ©.(z, Ï‰, [1 pÌ‚D], [0 pÌ‚F], [1 uÌ‚], [1 mÌ‚]), vcat, zplot), label=["not distorted" "distorted"], xlabel="Reported z | true z = 2")
png("z cond Ï‰=2")

# distribution of Ï‰ | z=2
z=2.; Ï‰plot=-3:.01:5; plot(Ï‰plot, mapreduce(Ï‰->[fÎ©condZ(Ï‰,z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,1.,0.,1.,1.) fÎ©condZ(Ï‰,z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,pÌ‚D,pÌ‚F,uÌ‚,mÌ‚)], vcat, Ï‰plot), label=["not distorted" "distorted"], xlabel="True z | reported z = 2")
png("Ï‰ cond z=2")

# frequentist CI's as fn of z
Ï‰plot=-5:.01:5; plot(Ï‰plot, ThreadsX.mapreduce(Ï‰->[Cquant.([.025 .5 .975], Ï‰, 1, 0, 1, 1)..., Cquant.([.025 .5 .975], Ï‰, pÌ‚D, pÌ‚F, uÌ‚, mÌ‚)...]',vcat,Ï‰plot), linecolor=[:blue :blue :blue :orange :orange :orange], linestyle=[:solid :dash :solid :solid :dash :solid], legend=false, xlabel="Reported z", ylabel="95% CI & median")
png("CI cond z")

# Bayesian posterior mean of Ï‰ as fn of Z
zplot=-5.:.1:5
pplot = mapreduce(z->[z EÎ©condZ(z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,1.,0.,1.,1.) EÎ©condZ(z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,pÌ‚D,pÌ‚F,uÌ‚, mÌ‚)], vcat, zplot)
plot(zplot, pplot, label=["As is" "shrinkage from informative prior" "shrinkage + adjustment for distortion"], xlabel="Reported z", ylabel="Expected true z")
png("E[Ï‰] cond z")

plot(zplot[zplot.>.2], pplot[zplot.>.2,2:3]./zplot[zplot.>.2], label=["shrinkage from informative prior" "shrinkage + adjustment for distortion"], xlabel="Reported z", ylabel="Discount multiplier")
png("E[Ï‰] discount")

println("Number of missing studies = ", size(df,1) * pÌ‚F * pÌ‚'*(@. cdf(Normal(Î¼,âˆš(1+Ï„^2)),ZÌ„)-cdf(Normal(Î¼,âˆš(1+Ï„^2)),-ZÌ„)))
println("Number of p-hacked studies = ", size(df,1) * (1-pÌ‚D-pÌ‚F) * pÌ‚'*(@. cdf(Normal(Î¼,âˆš(1+Ï„^2)),ZÌ„)-cdf(Normal(Î¼,âˆš(1+Ï„^2)),-ZÌ„)))

# CDF of z conditional on fitted parameters
p = vcat([[z  pÌ‚'cdf.(Normal.(Î¼Ì‚ , .âˆš(Ï„Ì‚ .^2 .+ 1)),z) HnFCDF(o,z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,pÌ‚D,pÌ‚F,uÌ‚, mÌ‚)] for z âˆˆ LinRange(-10:.1:10)]...)
plot(p[:,1], p[:,2:3], label=["Unfiltered" "Filtered"])


# van Zwet, Schwab, and Senn 2021 data, osf.io/xq4b2
df = DataFrame(CSV.File(raw"D:\OneDrive\Documents\Work\Clients & prospects\GiveWell\Noisy data\CochraneEffects.csv"))
@. @subset!(df, abs(:z) < 20 && :"outcome.nr"!=1 && :RCT=="yes" && :"outcome.group"=="efficacy")
# combine(groupby(df, :"study.id.sha1"), :z => sample => :z)  # randomly choose among primary outcomes
df.z .*= rand([-1. 1.], nrow(df))
histogram(df.z, normalize=:pdf, label="Actual published effects", legend=:topleft)

p = Float64[.3,.3,.3,.1]
Î¼ = [0.,0.,0.,0.]
Ï„ = [.61, 1.42, 2.16, 5.64]  # vZSS Table 1
pD = .99
pF = .01
pH = 1 - pD - pF
u = .75
m = 3.

o = HnFstuff(df.z, D=length(Î¼), interpres=300, quadnodes=25)
@time res = optimize(negHnFll(o), vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),SimplextoRâ¿([pD,pF,pH])...,logit(u),log(m)), LBFGS(), autodiff=:forward)
Î¸, ll = Optim.minimizer(res), Optim.minimum(res)
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, pÌ‚H, uÌ‚, mÌ‚ = Râ¿toSimplex(Î¸[1:o.D-1]), Î¸[o.D:2*o.D-1], exp.(Î¸[2*o.D:3*o.D-1]), Râ¿toSimplex(Î¸[3*o.D:3*o.D+1])..., logistic(Î¸[3*o.D+2]), exp(Î¸[3*o.D+3])
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚D=pÌ‚D, pÌ‚F=pÌ‚F, pÌ‚H=pÌ‚H, uÌ‚=uÌ‚, mÌ‚=mÌ‚))
println("Mean Ï‰ = ", pÌ‚'Î¼Ì‚)

ses = sqrt.(diag(pinv(ForwardDiff.hessian(negHnFll(o), Î¸))))

# Star Wars
df = DataFrame(CSV.File(raw"D:\OneDrive\Documents\Work\Library\Meta-science\Brodeur et al. 2016\Data\Final\final_stars_supp.csv"))
@. @subset!(df, lowercase(:main)=="yes")
df = DataFrame(Dict(:z => df.coefficient_num ./ df.standard_deviation_num))
dropmissing!(df)
@subset!(df, abs.(:z).<20)
df.z = Float64.(df.z)
histogram(abs.(df.z), normalize=:pdf, bins=1000)

p = [.3,.3,.4]
Î¼ = 0.
Ï„ = [1.,2.,3.]
pD = .5
pF = .25
pH = 1 - pD - pF
u = .75
m = 3.

o = HnFstuff(df.z, D=length(Ï„), interpres=300, quadnodes=25)
@time res = optimize(negHnFllSharedÎ¼(o), vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),SimplextoRâ¿([pD,pF,pH])...,logit(u),log(m)), LBFGS(), autodiff=:forward)
Î¸, ll = Optim.minimizer(res), Optim.minimum(res)
# pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, pÌ‚H, uÌ‚, mÌ‚ = Râ¿toSimplex(Î¸[1:o.D-1]), Î¸[o.D:2*o.D-1], exp.(Î¸[2*o.D:3*o.D-1]), Râ¿toSimplex(Î¸[3*o.D:3*o.D+1])..., logistic(Î¸[3*o.D+2]), exp(Î¸[3*o.D+3])
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, pÌ‚H, uÌ‚, mÌ‚ = Râ¿toSimplex(Î¸[1:o.D-1]), Î¸[o.D], exp.(Î¸[o.D+1:2*o.D]), Râ¿toSimplex(Î¸[2*o.D+1:2*o.D+2])..., logistic(Î¸[2*o.D+3]), exp(Î¸[2*o.D+4])
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚D=pÌ‚D, pÌ‚F=pÌ‚F, pÌ‚H=pÌ‚H, uÌ‚=uÌ‚, mÌ‚=mÌ‚))
ses = sqrt.(diag(pinv(ForwardDiff.hessian(negHnFllSharedÎ¼(o), Î¸))))
