using Random, Distributions, Interpolations, Base.Iterators, FastGaussQuadrature, BenchmarkTools, Optim, LogExpFunctions, Plots, CSV, DataFrames, DataFramesMeta, ForwardDiff, LinearAlgebra, Roots, QuadGK, Statistics, ThreadsX

const ZÌ„ = 1.9599639845401

@inline diffcdf(N,b,a) = cdf(N,b) - cdf(N,a)
@inline diffpdf(N,b,a) = pdf(N,b) - pdf(N,a)

import Base.rand, Distributions.pdf, Distributions.logpdf, Distributions.cdf, Distributions.logcdf, Distributions.ccdf, Distributions.logccdf, Statistics.quantile

# type to represent distribution of maximum of m normal draws, Float64 only
struct MaxNormal <: Distribution{Univariate, Continuous}
	m::Float64  # number of draws over which to take max
	invm::Float64
	Î¼::Float64  # mean
	Ïƒ::Float64  # sd
	ğ’©::Normal{Float64}
	MaxNormal(m=1., Î¼=0., Ïƒ=1.) = new(m,1/m,Î¼,Ïƒ,Normal(Î¼,Ïƒ))
end
cdf(s::MaxNormal, x::Float64) = cdf(s.ğ’©,x) ^ s.m
logccdf(s::MaxNormal, x::Float64) = log1mexp(s.m * logcdf(s.ğ’©,x))
ccdf(s::MaxNormal, x::Float64) = exp(logccdf(s,x))
pdf(s::MaxNormal, x::Float64) = pdf(s.ğ’©,x) * s.m * cdf(s.ğ’©,x)^(s.m-1)
logpdf(s::MaxNormal, x::Float64) = logpdf(s.ğ’©,x) + log(s.m) + (s.m-1) * logcdf(s.ğ’©,x)
quantile(s::MaxNormal, x::Float64) = quantile(s.ğ’©, x^s.invm)
rand(rng::AbstractRNG, s::MaxNormal) = quantile(s.ğ’©, rand(rng)^s.invm)

struct MinNormal <: Distribution{Univariate, Continuous}
	m::Float64  # number of draws over which to take max
	invm::Float64
	Î¼::Float64  # mean
	Ïƒ::Float64  # sd
	ğ’©::Normal{Float64}
	MinNormal(m=1., Î¼=0., Ïƒ=1.) = new(m,1/m,Î¼,Ïƒ,Normal(Î¼,Ïƒ))
end
cdf(s::MinNormal, x::Float64) = exp(logcdf(s,x))
logcdf(s::MinNormal, x::Float64) = log1mexp(s.m * logccdf(s.ğ’©,x))
ccdf(s::MinNormal, x::Float64) = ccdf(s.ğ’©,x) ^ s.m
pdf(s::MinNormal, x::Float64) = pdf(s.ğ’©,x) * s.m * ccdf(s.ğ’©,x)^(s.m-1)
logpdf(s::MinNormal, x::Float64) = logpdf(s.ğ’©,x) + log(s.m) + (s.m-1) * logccdf(s.ğ’©,x)
quantile(s::MinNormal, x::Float64) = cquantile(s.ğ’©, (1-x)^s.invm)
rand(rng::AbstractRNG, s::MinNormal) = cquantile(s.ğ’©, rand(rng)^s.invm)

# to parameterize an n-vector of probabilities summing to 1 with an unbounded (n-1)-vector, apply logistic transform to latter, then map to squared spherical coordinates
# https://en.wikipedia.org/wiki/N-sphere#Spherical_coordinates, https://math.stackexchange.com/questions/2861449/parameterizations-of-the-unit-simplex-in-mathbbr3
function Râ¿toSimplex(q::Vector{T}) where T
	_q = logistic.(q)
	p = Vector{T}(undef, length(q)+1)
	Î sinÂ² = one(T)
	for i âˆˆ eachindex(_q)
		cosÂ² = cospi(_q[i])^2
		p[i] = Î sinÂ² * cosÂ²
		Î sinÂ² *= one(T) - cosÂ²
	end
	p[end] = Î sinÂ²
	p
end
function SimplextoRâ¿(p::Vector{T}) where T
	q = Vector{T}(undef, length(p)-1)
	sum = p[end]
	for i âˆˆ reverse(eachindex(q))
		sum += p[i]
		q[i] = acos(âˆš(p[i] / sum)) / Ï€
	end
	q .= logit.(q)
end

# unlogged likelihood for a single observation. For graphs.
function HnFl(z; p::Vector, Î¼::Vector, Ï„::Vector, pFâ‚€, pLâ‚€, pUâ‚€, kL=0, kU=0, m=1, truncate=true)
	ZÌ„L	= min(ZÌ„, 1/kL-ZÌ„)
	ZÌ„U	= min(ZÌ„, 1/kU-ZÌ„)
	pDâ‚€ = 1 - pFâ‚€
	length(p) < length(Î¼) && (p = [p; 1-sum(p)])
	ÏƒÂ² = 1 .+ Ï„.^2
	ğ’©  = Normal()
	ğ’©Î¼ = @. Normal(Î¼, âˆšÏƒÂ²)
	ğ’©Ï‰ = @. NormalCanon(z + Î¼/Ï„^2, 1 + 1/Ï„^2)
	if abs(z) â‰¥ ZÌ„
		result = 0.
		@inbounds for (páµ¢,ğ’©Î¼áµ¢,ğ’©Ï‰áµ¢) âˆˆ zip(p,ğ’©Î¼,ğ’©Ï‰)
			if z < 0
				result += páµ¢ * pdf(ğ’©Î¼áµ¢, z) * (1 + m * pLâ‚€ * quadgk(Ï‰ -> (a = pdf(ğ’©Ï‰áµ¢,Ï‰) * ((1-kL*(ZÌ„+Ï‰))*diffcdf(ğ’©,ZÌ„L-Ï‰,-ZÌ„-Ï‰) + kL*diffpdf(ğ’©,ZÌ„L-Ï‰,-ZÌ„-Ï‰)) * ccdf(ğ’©,z-Ï‰)^(m-1) / (1-ccdf(ğ’©,-ZÌ„-Ï‰)^m);
																										              isnan(a) || isinf(a) ? 0. : a), 
																                            -Inf, Inf)[1])
			else
				result += páµ¢ * pdf(ğ’©Î¼áµ¢, z) * (1 + m * pUâ‚€ * quadgk(Ï‰ -> (a = pdf(ğ’©Ï‰áµ¢,Ï‰) * ((1-kU*(ZÌ„-Ï‰))*diffcdf(ğ’©,ZÌ„-Ï‰,-ZÌ„U-Ï‰) - kU*diffpdf(ğ’©,ZÌ„-Ï‰,-ZÌ„U-Ï‰)) * cdf(ğ’©,z-Ï‰)^(m-1) / (1 - cdf(ğ’©, ZÌ„-Ï‰)^m);
																										              isnan(a) || isinf(a) ? 0. : a), 
																                            -Inf, Inf)[1])
			end
		end
	else
		result = dot(p, pdf.(ğ’©Î¼, z)) * pDâ‚€ * (1 - pLâ‚€ * max(0, 1-kL*(ZÌ„+z)) - pUâ‚€ * max(0, 1-kU*(ZÌ„-z)))
	end
	truncate && (result /= 1 - pFâ‚€ * dot(p, @. diffcdf(ğ’©Î¼,ZÌ„,-ZÌ„) - pLâ‚€ * ((1-kL*(ZÌ„+Î¼)) * diffcdf(ğ’©Î¼,ZÌ„L,-ZÌ„) + kL * ÏƒÂ² * diffpdf(ğ’©Î¼,ZÌ„L,-ZÌ„)) - 
	                                                               pUâ‚€ * ((1-kU*(ZÌ„-Î¼)) * diffcdf(ğ’©Î¼,ZÌ„,-ZÌ„U) + kU * ÏƒÂ² * diffpdf(ğ’©Î¼,ZÌ„,-ZÌ„U))   ))
	result
end

# object to hold pre-computed stuff for log likelihood computation
struct HnFstuff
	D::Int  # number of mixture components
	z::Vector{Float64}  # all data
	zC::Vector{Float64}  # just the central, insignificant z's
	N::Int; NC::Int; NL::Int; NU::Int  # number of z's, insigficant z's, lower significant z's, upper
	knots::LinRange  # interpolation knots in [ZÌ„,max]
	spline::Interpolations.InterpolationType  # type of interpolation
	zSint::NTuple{2,Vector{Float64}}  # lower- & upper-tail significant z values mapped to cardinal knot numbering space since interpolate() is faster with cardinally spaced knots
	X::Vector{Float64}; W::Vector{Float64}  # quadrature nodes & weights
	lnW::Vector{Float64}
end
# constructor
function HnFstuff(z::Vector{Float64}; D::Int, interpres::Int, quadnodes::Int)
	zC = z[abs.(z) .< ZÌ„]

	s = ZÌ„ - 3/interpres; e = max(10,maximum(z))+.1
	knots = s : 1/interpres : e  # LinRange(s, e, ceil(Int, (e - s) * interpres) + 1)
	zSint = (-z[z .â‰¤ -ZÌ„] .- s) .* interpres .+ 1, (z[z .â‰¥ ZÌ„] .- s) .* interpres .+ 1  # map tail z values to knot numbering 1, 2, ... for ZÌ„-3/interpres, ZÌ„-2/interpres, ...
	
	X, W = gausshermite(quadnodes)
	W ./= âˆšÏ€
	
	HnFstuff(D, z, zC, length(z), length(zC), length.(zSint)..., knots, BSpline(Quadratic(Free(OnGrid()))), zSint, X, W, log.(W))
end

try Base.delete_method.(methods(HnFll)) catch end
# bulk log probabilities as function of data & parameters, for estimation
function HnFll(o::HnFstuff, p::Vector{T}, Î¼::Vector, Ï„::Vector{T}, pFâ‚€::T, pLâ‚€::T, pUâ‚€::T, kL::T, kU::T, m::T) where T<:Real
	Ï„ = exp.(Ï„)
	kL = exp(kL)
	kU = exp(kU)
	m = exp(m); mm1 = m - one(T)
	p = Râ¿toSimplex(p)
	pFâ‚€ = logistic(pFâ‚€)
	pLâ‚€ = logistic(pLâ‚€)
	pUâ‚€ = logistic(pUâ‚€)
	pLâ‚€+pUâ‚€>1 && return(T(NaN))
	pDâ‚€ = 1 - pFâ‚€
	pH = [m*pLâ‚€*exp(kL*(kL/2-ZÌ„)), m*pUâ‚€*exp(kU*(kU/2-ZÌ„))]
	LC = fill(zero(T), o.NC)  # likelihood for insignificant obs
	LS = fill(zero(T), o.NL), fill(zero(T), o.NU)  # for significant obs, left & right tails

	ÏƒÂ² = 1 .+ (Ï„Â² = Ï„.^2)
	ğ’©  = Normal()
	ğ’©Î¼ = Normal.(Î¼, .âˆšÏƒÂ²)

	for (páµ¢,Î¼áµ¢,Ï„áµ¢Â²,Ïƒáµ¢Â²,ğ’©Î¼áµ¢) âˆˆ zip(p,Î¼,Ï„Â²,ÏƒÂ²,ğ’©Î¼)
		# math on integration and interpolation points, outside loops
		Î©  = o.X * âˆš(2Ï„áµ¢Â² / Ïƒáµ¢Â²)  # 1st-order component of change of variables from pdf(Normal(Ï‰)) to exp(-xÂ²) for Gauss-Hermite quadrature
		Î©L = -ZÌ„ .- Î©
		Î©U =  ZÌ„ .- Î©
		ğ’©Î© = Normal.(Î©)

		buf = Vector{T}(undef, length(o.knots))  # pre-allocating this hampers automatic differentiation since type changes

		# lower tail
		kt1 = collect((Î¼áµ¢/Ï„áµ¢Â² .- o.knots) * -Ï„áµ¢Â²/Ïƒáµ¢Â²)  #    -(z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points -- negated 0th-order component of change of variables for quadrature
		kt2 = collect(kt1 - o.knots                 )  # z - (z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points
		fill!(buf, zero(T))
		@inbounds Threads.@threads for j âˆˆ eachindex(o.knots)
			kt1j, kt2j = kt1[j], kt2[j]
			for (ğ’©Ï‰,Ï‰,Ï‰l,Ï‰u,lnw) âˆˆ zip(ğ’©Î©,Î©,Î©L,Î©U,o.lnW)  # quadrature integration
				buf[j] += exp(lnw - kL * (Ï‰ - kt1j) + logdiffcdf(ğ’©, kt1j + Ï‰u + kL, kt1j + Ï‰l + kL) + mm1 * logccdf(ğ’©Ï‰, kt2j) - log1mexp(m * logccdf(ğ’©, kt1j + Ï‰l)))
			end
		end
		@. buf = páµ¢ * pdf(ğ’©Î¼áµ¢, -o.knots) * (one(T) + pH[1] * buf)
		LS[1] .+= interpolate!(buf, o.spline).(o.zSint[1])  # likelihoods for significant observations

		# upper tail
		kt1 .= collect((Î¼áµ¢/Ï„áµ¢Â² .+ o.knots) * -Ï„áµ¢Â²/Ïƒáµ¢Â²)  #    -(z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points
		kt2 .= collect(kt1 + o.knots                 )  # z - (z+Î¼áµ¢â„Ï„áµ¢Â²)/(1+1â„Ï„áµ¢Â²) for z at interpolation points
		fill!(buf, zero(T))
		@inbounds Threads.@threads for j âˆˆ eachindex(o.knots)
			kt1j, kt2j = kt1[j], kt2[j]
			for (ğ’©Ï‰,Ï‰,Ï‰l,Ï‰u,lnw) âˆˆ zip(ğ’©Î©,Î©,Î©L,Î©U,o.lnW)  # quadrature integration
				buf[j] += exp(lnw + kU * (Ï‰ - kt1j) + logdiffcdf(ğ’©, kt1j + Ï‰u - kU, kt1j + Ï‰l - kU) + mm1 * logcdf(ğ’©Ï‰, kt2j) - log1mexp(m * logcdf(ğ’©, kt1j + Ï‰u)))
			end
		end
		@. buf = páµ¢ * pdf(ğ’©Î¼áµ¢, o.knots) * (one(T) + pH[2] * buf)
		LS[2] .+= interpolate!(buf, o.spline).(o.zSint[2])  # likelihoods for significant observations

		@. LC += páµ¢ * pdf(ğ’©Î¼áµ¢, o.zC)  # likelihoods for center/insignificant observations
	end
# XXX move interpolation out of above loop and interpolate log likelihood instead?
# XXX precompute ZÌ„ + o.zC, ZÌ„ - o.zC
	mapreduce(v->ThreadsX.mapreduce(log, +, v, init=zero(T)), +, (LC, LS...)) +
		o.NC * log(pDâ‚€) + mapreduce(z->log1p(- pLâ‚€ * exp(-kL * (ZÌ„ + z)) - pUâ‚€ * exp(-kU * (ZÌ„ - z))), +, o.zC, init=zero(T)) - 
    xlog1py(o.N, -pFâ‚€ * dot(p, @. diffcdf(ğ’©Î¼,ZÌ„,-ZÌ„) - pLâ‚€ * exp(kL*(ÏƒÂ²*kL/2-Î¼-ZÌ„)) * diffcdf(ğ’©Î¼, ZÌ„+ÏƒÂ²*kL, -ZÌ„+ÏƒÂ²*kL) -
		                                                  pUâ‚€ * exp(kU*(ÏƒÂ²*kU/2+Î¼-ZÌ„)) * diffcdf(ğ’©Î¼, ZÌ„-ÏƒÂ²*kU, -ZÌ„-ÏƒÂ²*kU)))
end

# log likelihood--function of parameters only
negHnFll(o)        = v -> -HnFll(o, v[1:o.D-1], v[o.D:2*o.D-1], v[2*o.D:3*o.D-1], v[3*o.D:end]...)
negHnFll0cent(o)   = v -> -HnFll(o, v[1:o.D-1], zeros(Float64,o.D), v[o.D:2*o.D-1], v[2*o.D:end]...)  # impose Î¼=0
negHnFllSharedÎ¼(o) = v -> -HnFll(o, v[1:o.D-1], fill(v[o.D],o.D), v[o.D+1:2*o.D], v[2*o.D+1:end]...) # impose shared Î¼

function HnFCDF(o::HnFstuff, z::T, p::Vector{T}, Î¼::Vector{T}, Ï„::Vector{T}, pDâ‚€::T, pF::T, U) where T<:Number
	pH = 1 - pD - pF

	ğ’©H = Normal.(âˆš2Ï„ * o.X' .+ Î¼)
	ğ’©  = Normal.(Î¼, .âˆš(1 .+ Ï„.^2))

	a = cdf.(ğ’©H, -ZÌ„)
	b = ccdf.(ğ’©H, ZÌ„)
	if z â‰¤ ZÌ„  # tails
		result = pH * p'* cdf.(ğ’©, min(z,-ZÌ„)                          ) + pH * (p' * ( cdf.(ğ’©H, min(z,-ZÌ„))       .* (one(T) .- a .- b) ./ (a .+ U .* b)) * o.W)
	else
		result = pH * p'*(cdf.(ğ’©,       -ZÌ„) + cdf.(ğ’©,z) - cdf.(ğ’©,ZÌ„)) + pH * (p' * ((a + U * (cdf.(ğ’©H,z) - b)) .* (one(T) .- a .- b) ./ (a .+ U .* b)) * o.W)
	end
	z > -ZÌ„ &&  # central bit
		(result += pD * (p' * (cdf.(ğ’©, min(z,ZÌ„)) - cdf.(ğ’©,-ZÌ„))))
	result / (1 - pF * (p' * (cdf.(ğ’©,ZÌ„) - cdf.(ğ’©,-ZÌ„))))
end

# f(z|Ï‰)
function fZcondÎ©(z, Ï‰; pFâ‚€, pLâ‚€, pUâ‚€, kL, kU, m, truncate=true)
	pDâ‚€ = 1 - pFâ‚€
	result = abs(z) < ZÌ„ ? pdf(Normal(Ï‰),z) * pDâ‚€ * (1 - pLâ‚€ * exp(-kL*(ZÌ„+z)) - pUâ‚€ * exp(-kU*(ZÌ„-z))) :
							          pdf(Normal(Ï‰),z) + exp(z < 0 ? logpdf(MinNormal(m,Ï‰),z) - logcdf( MinNormal(m,Ï‰),-ZÌ„) + log(pLâ‚€) + kL*(kL/2-ZÌ„-Ï‰) + logdiffcdf(Normal(Ï‰-kL),ZÌ„,-ZÌ„) :
											                                 logpdf(MaxNormal(m,Ï‰),z) - logccdf(MaxNormal(m,Ï‰), ZÌ„) + log(pUâ‚€) + kU*(kU/2-ZÌ„+Ï‰) + logdiffcdf(Normal(Ï‰+kU),ZÌ„,-ZÌ„)  )
	truncate && (result /= (1 - pFâ‚€ * (diffcdf(Normal(Ï‰), ZÌ„,-ZÌ„) - pLâ‚€ * exp(kL*(kL/2-ZÌ„-Ï‰)) * diffcdf(Normal(Ï‰-kL),ZÌ„,-ZÌ„) - pUâ‚€ * exp(kU*(kU/2-ZÌ„-Ï‰)) * diffcdf(Normal(Ï‰+kU),ZÌ„,-ZÌ„))))
	isnan(result) || isinf(result) ? 0. : result
end

# F(z|Ï‰)
function FZcondÎ©(z, Ï‰; pFâ‚€, pLâ‚€, pUâ‚€, kL, kU, m)
	pDâ‚€ = 1 - pFâ‚€
	ğ’© = Normal(Ï‰)
	D = diffcdf(Normal(Ï‰), ZÌ„,-ZÌ„) - pLâ‚€ * exp(kL*(kL/2-ZÌ„-Ï‰)) * diffcdf(Normal(Ï‰-kL),ZÌ„,-ZÌ„) - 
	                               pUâ‚€ * exp(kU*(kU/2-ZÌ„-Ï‰)) * diffcdf(Normal(Ï‰+kU),ZÌ„,-ZÌ„)  # P[no p-hack]
	if z > ZÌ„  # tails
		ğ’©max = MaxNormal(m,Ï‰)
		result = 1 - (pUâ‚€ * exp(logccdf(ğ’©max,z) - logccdf(ğ’©max,ZÌ„) + kU*(kU/2-ZÌ„+Ï‰) + logdiffcdf(ğ’©, ZÌ„, -ZÌ„)) + ccdf(ğ’©,z)) / (1 - pFâ‚€ * D)
	else
		if z < -ZÌ„
			ğ’©min = MinNormal(m,Ï‰)
			result =    pLâ‚€ * exp(logcdf(ğ’©min, z) - logcdf(ğ’©min, -ZÌ„) + kL*(kL/2-ZÌ„-Ï‰) + logdiffcdf(ğ’©, kL+ZÌ„, kL-ZÌ„)) + cdf(ğ’©,z)
		else
			result =    pLâ‚€ * exp(                                       kL*(kL/2-ZÌ„-Ï‰) + logdiffcdf(ğ’©, kL+ZÌ„, kL-ZÌ„)) + cdf(ğ’©,-ZÌ„) + 
			                pDâ‚€ * (diffcdf(Normal(Ï‰), z,-ZÌ„) - pLâ‚€ * exp(kL*(kL/2-ZÌ„-Ï‰)) * diffcdf(Normal(Ï‰-kL),z,-ZÌ„) - 
											                                  pUâ‚€ * exp(kU*(kU/2-ZÌ„-Ï‰)) * diffcdf(Normal(Ï‰+kU),z,-ZÌ„)  )
		end
		result /= 1 - pFâ‚€ * D
	end
	result
end


# f(z), f(Ï‰), f(Ï‰|z), E[Ï‰|z]
fZ = HnFl
fÎ©(Ï‰; p, Î¼, Ï„) = p'pdf.(Normal.(Î¼,Ï„), Ï‰)
fÎ©condZ(Ï‰, z; p, Î¼, Ï„, kwargs...) = fZcondÎ©(z, Ï‰; kwargs..., truncate=false) * fÎ©(Ï‰; p, Î¼, Ï„) / fZ(z; p, Î¼, Ï„, kwargs..., truncate=false)
EÎ©condZ(z; p, Î¼, Ï„, kwargs...) = quadgk(Ï‰->Ï‰ * fÎ©condZ(Ï‰, z; p, Î¼, Ï„, kwargs...), -Inf, Inf)[1]

# CIs
Cquant(Î±, z; kwargs...) = find_zero(Ï‰ -> Î± - FZcondÎ©(z, Ï‰; kwargs...), (-20,20))
CI(Î±, z; kwargs...) = Cquant(Î±/2, z; kwargs...), Cquant(1-Î±/2, z; kwargs...)


function HnFDGP(N; p::Vector, Î¼::Vector, Ï„::Vector, pFâ‚€, pLâ‚€, pUâ‚€, kL=0, kU=0, m=1, truncate=true, Ï‰=NaN)
	isone(length(Î¼)) && (Î¼ = fill(Î¼[], length(Ï„)))
	length(p) < length(Î¼) && (p = [p; 1-sum(p)])
	I = rand(Categorical(p), N)
	Î© = isnan(Ï‰) ? map(i->rand(Normal(Î¼[i], Ï„[i])), I) : fill(Ï‰,N)
	Zâœ» = rand.(Normal.(Î©))
	Z = similar(Zâœ»)
	@inbounds Threads.@threads for i âˆˆ eachindex(Zâœ»)
		Zâœ»áµ¢ = Zâœ»[i]
		if abs(Zâœ»áµ¢) > ZÌ„
			Z[i] = Zâœ»áµ¢  # publish significant result as is
		else
			pL = pLâ‚€ * max(0, 1-kL*(ZÌ„ + Zâœ»áµ¢))
			pU = pUâ‚€ * max(0, 1-kU*(ZÌ„ - Zâœ»áµ¢))
			pF = pFâ‚€ * (1 - pL - pU)
			pD = 1 - pL - pU - pF
			r = rand()
			if r < pD
				Z[i] = Zâœ»áµ¢  # publish insignificant result as is
			elseif r < pD + pF
				Z[i] = NaN  # file-drawer
			elseif r < pD + pF + pL
				ğ’© = MinNormal(m,Î©[i])
				Z[i] = quantile(ğ’©, rand(Uniform(0., cdf(ğ’©, -ZÌ„))))  # hack to lower tail
			else
				ğ’© = MaxNormal(m,Î©[i])
				Z[i] = quantile(ğ’©, rand(Uniform(cdf(ğ’©, ZÌ„), 1.)))  # hack to upper tail
			end
		end
	end
	if truncate
		keep = @. !isnan(Z) && abs(Z)<10
		Î©=Î©[keep]
		Zâœ»=Zâœ»[keep]
		Z=Z[keep]
	end
	(Î©=Î©, Zâœ»=Zâœ», Z=Z)  # named tuple with results
end


# confirm match between model and simulation
pFâ‚€ = .3
pLâ‚€ = .3
pUâ‚€ = .3
kL = 10.
kU = 10.
p = [1.]
Î¼ = [0.]
Ï„ = [2.]
m = 5.

z = HnFDGP(3_000_000; p, Î¼, Ï„, pFâ‚€, pLâ‚€, pUâ‚€, kL, kU, m, truncate=true).Z

histogram(z, normalize=:pdf, legend=false)
zplot = -10:.1:10
pplot = map(z->HnFl(z; p, Î¼, Ï„, pFâ‚€, pLâ‚€, pUâ‚€, kL, kU, m, truncate=true), zplot)
plot!(zplot, pplot)
plot!(zplot, map(z->exp(-negHnFll(HnFstuff([z], D=length(Î¼), interpres=300, quadnodes=25))(vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),logit(pFâ‚€),logit(pLâ‚€),logit(pUâ‚€),log(kL),log(kU),log(m)))),zplot))

o = HnFstuff(z, D=length(Î¼), interpres=300, quadnodes=25)
@time res = optimize(negHnFll(o), vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),logit(pFâ‚€),logit(pLâ‚€),logit(pUâ‚€),log(kL),log(kU),log(m)), LBFGS(), autodiff=:forward)
Î¸â‚‚ = Optim.minimizer(res)
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚Fâ‚€, pÌ‚Lâ‚€, pÌ‚Uâ‚€, kÌ‚L, kÌ‚U, mÌ‚ = Râ¿toSimplex(Î¸â‚‚[1:o.D-1]), Î¸â‚‚[o.D:2*o.D-1], exp.(Î¸â‚‚[2*o.D:3*o.D-1]), logistic(Î¸â‚‚[3*o.D]), logistic(Î¸â‚‚[3*o.D+1]), logistic(Î¸â‚‚[3*o.D+2]), exp(Î¸â‚‚[3*o.D+3]), exp(Î¸â‚‚[3*o.D+4]), exp(Î¸â‚‚[3*o.D+5])
pÌ‚Dâ‚€ = 1 - pÌ‚Fâ‚€
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚Fâ‚€=pÌ‚Fâ‚€, pÌ‚Lâ‚€=pÌ‚Lâ‚€, pÌ‚Uâ‚€=pÌ‚Uâ‚€, kÌ‚L=kÌ‚L, kÌ‚U=kÌ‚U, mÌ‚=mÌ‚))

plot!(zplot, map(z->HnFl(z; p=pÌ‚, Î¼=Î¼Ì‚ , Ï„=Ï„Ì‚ , pFâ‚€=pÌ‚Fâ‚€, pLâ‚€=pÌ‚Lâ‚€, pUâ‚€=pÌ‚Uâ‚€, kL=kÌ‚L, kU=kÌ‚U, m=mÌ‚), zplot))


# data prep
df = DataFrame(CSV.File(raw"D:\OneDrive\Documents\Work\Clients & prospects\GiveWell\Noisy data\Georgescu.Wren.csv"))
@. df.cilevel[ismissing(df.cilevel) || df.cilevel==.0095 || df.cilevel==.05] = .95
@. df.z = log(df.mean) / (ifelse(ismissing(df.lower) || iszero(df.lower), log(df.upper / df.mean), log(df.upper / df.lower) / 2) / cquantile(Normal(), (1 - df.cilevel)/2.))
@. @subset!(df, !ismissing(:z) && !ismissing(:lower))
@. @subset!(df, iszero(:mistake) && abs(:z) < 10.)
@. @subset!(df, :source!="Abstract")
df.z = Float64.(df.z)
histogram(df.z, normalize=:pdf, label="Actual published effects", legend=:topleft)

# fit 2-component min/max model
p = Float64[.5,.5]
Î¼ = [0.,0.]
Ï„ = [1.,2.]
pD = .4
pF = .5
pH = 1 - pD - pF
u = .75
m = 3.

o = HnFstuff(df.z, D=length(Î¼), interpres=300, quadnodes=25)
@time res2 = optimize(negHnFll(o), vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),SimplextoRâ¿([pD,pF,pH])...,logit(u),log(m)), LBFGS(), autodiff=:forward)
Î¸, ll = Optim.minimizer(res2), Optim.minimum(res2)
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, pÌ‚H, uÌ‚, mÌ‚ = Râ¿toSimplex(Î¸[1:o.D-1]), Î¸[o.D:2*o.D-1], exp.(Î¸[2*o.D:3*o.D-1]), Râ¿toSimplex(Î¸[3*o.D:3*o.D+1])..., logistic(Î¸[3*o.D+2]), exp(Î¸[3*o.D+3])
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚D=pÌ‚D, pÌ‚F=pÌ‚F, pÌ‚H=pÌ‚H, uÌ‚=uÌ‚, mÌ‚=mÌ‚))
println("Mean Ï‰ = ", pÌ‚'Î¼Ì‚)
ses2 = sqrt.(diag(pinv(ForwardDiff.hessian(negHnFll(o), Î¸â‚‚))))

zplot = -10:.1:10
pplotfit = map(z->HnFl(z, pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, uÌ‚, mÌ‚), zplot)
plt = histogram(df.z, normalize=:pdf, label="Actual published estimates", legend=:topleft)
plot!(zplot, [pÌ‚[1] * pdf.(Normal(Î¼Ì‚[1],Ï„Ì‚[1]), zplot)+pÌ‚[2] * pdf.(Normal(Î¼Ì‚[2],Ï„Ì‚[2]), zplot) pÌ‚[1] * pdf.(Normal(Î¼Ì‚[1],âˆš(1+Ï„Ì‚[1]^2)), zplot)+pÌ‚[2] * pdf.(Normal(Î¼Ì‚[2],âˆš(1+Ï„Ì‚[2]^2)), zplot) pplotfit], label=["Model: true effects" "Model: initial estimates" "Model: published estimates"])
png(plt, "fit")
plt

# distribution of z | Ï‰=2
Ï‰=2; zplot=-3:.01:5; plot(zplot, mapreduce(z->fZcondÎ©.(z, Ï‰, [1 pÌ‚D], [0 pÌ‚F], [1 uÌ‚], [1 mÌ‚]), vcat, zplot), label=["not distorted" "distorted"], xlabel="Reported z | true z = 2")
png("z cond Ï‰=2")

# distribution of Ï‰ | z=2
z=2.; Ï‰plot=-3:.01:5; plot(Ï‰plot, mapreduce(Ï‰->[fÎ©condZ(Ï‰,z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,1.,0.,1.,1.) fÎ©condZ(Ï‰,z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,pÌ‚D,pÌ‚F,uÌ‚,mÌ‚)], vcat, Ï‰plot), label=["not distorted" "distorted"], xlabel="True z | reported z = 2")
png("Ï‰ cond z=2")

# frequentist CI's as fn of z
Ï‰plot=-5:.01:5; plot(Ï‰plot, ThreadsX.mapreduce(Ï‰->[Cquant.([.025 .5 .975], Ï‰, 1, 0, 1, 1)..., Cquant.([.025 .5 .975], Ï‰, pÌ‚D, pÌ‚F, uÌ‚, mÌ‚)...]',vcat,Ï‰plot), linecolor=[:blue :blue :blue :orange :orange :orange], linestyle=[:solid :dash :solid :solid :dash :solid], legend=false, xlabel="Reported z", ylabel="95% CI & median")
png("CI cond z")

# Bayesian posterior mean of Ï‰ as fn of Z
zplot=-5.:.1:5
pplot = mapreduce(z->[z EÎ©condZ(z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,1.,0.,1.,1.) EÎ©condZ(z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,pÌ‚D,pÌ‚F,uÌ‚, mÌ‚)], vcat, zplot)
plot(zplot, pplot, label=["As is" "shrinkage from informative prior" "shrinkage + adjustment for distortion"], xlabel="Reported z", ylabel="Expected true z")
png("E[Ï‰] cond z")

plot(zplot[zplot.>.2], pplot[zplot.>.2,2:3]./zplot[zplot.>.2], label=["shrinkage from informative prior" "shrinkage + adjustment for distortion"], xlabel="Reported z", ylabel="Discount multiplier")
png("E[Ï‰] discount")

println("Number of missing studies = ", size(df,1) * pÌ‚F * pÌ‚'*(@. cdf(Normal(Î¼,âˆš(1+Ï„^2)),ZÌ„)-cdf(Normal(Î¼,âˆš(1+Ï„^2)),-ZÌ„)))
println("Number of p-hacked studies = ", size(df,1) * (1-pÌ‚D-pÌ‚F) * pÌ‚'*(@. cdf(Normal(Î¼,âˆš(1+Ï„^2)),ZÌ„)-cdf(Normal(Î¼,âˆš(1+Ï„^2)),-ZÌ„)))

# CDF of z conditional on fitted parameters
p = vcat([[z  pÌ‚'cdf.(Normal.(Î¼Ì‚ , .âˆš(Ï„Ì‚ .^2 .+ 1)),z) HnFCDF(o,z,pÌ‚,Î¼Ì‚ ,Ï„Ì‚ ,pÌ‚D,pÌ‚F,uÌ‚, mÌ‚)] for z âˆˆ LinRange(-10:.1:10)]...)
plot(p[:,1], p[:,2:3], label=["Unfiltered" "Filtered"])


# van Zwet, Schwab, and Senn 2021 data, osf.io/xq4b2
df = DataFrame(CSV.File(raw"D:\OneDrive\Documents\Work\Clients & prospects\GiveWell\Noisy data\CochraneEffects.csv"))
@. @subset!(df, abs(:z) < 20 && :"outcome.nr"!=1 && :RCT=="yes" && :"outcome.group"=="efficacy")
# combine(groupby(df, :"study.id.sha1"), :z => sample => :z)  # randomly choose among primary outcomes
df.z .*= rand([-1. 1.], nrow(df))
histogram(df.z, normalize=:pdf, label="Actual published effects", legend=:topleft)

p = Float64[.3,.3,.3,.1]
Î¼ = [0.,0.,0.,0.]
Ï„ = [.61, 1.42, 2.16, 5.64]  # vZSS Table 1
pD = .99
pF = .01
pH = 1 - pD - pF
u = .75
m = 3.

o = HnFstuff(df.z, D=length(Î¼), interpres=300, quadnodes=25)
@time res = optimize(negHnFll(o), vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),SimplextoRâ¿([pD,pF,pH])...,logit(u),log(m)), LBFGS(), autodiff=:forward)
Î¸, ll = Optim.minimizer(res), Optim.minimum(res)
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚D, pÌ‚F, pÌ‚H, uÌ‚, mÌ‚ = Râ¿toSimplex(Î¸[1:o.D-1]), Î¸[o.D:2*o.D-1], exp.(Î¸[2*o.D:3*o.D-1]), Râ¿toSimplex(Î¸[3*o.D:3*o.D+1])..., logistic(Î¸[3*o.D+2]), exp(Î¸[3*o.D+3])
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚D=pÌ‚D, pÌ‚F=pÌ‚F, pÌ‚H=pÌ‚H, uÌ‚=uÌ‚, mÌ‚=mÌ‚))
println("Mean Ï‰ = ", pÌ‚'Î¼Ì‚)

ses = sqrt.(diag(pinv(ForwardDiff.hessian(negHnFll(o), Î¸))))

# Star Wars
df = DataFrame(CSV.File(raw"D:\OneDrive\Documents\Work\Library\Meta-science\Brodeur et al. 2016\Data\Final\final_stars_supp.csv"))
@. @subset!(df, lowercase(:main)=="yes")
df = DataFrame(Dict(:z => df.coefficient_num ./ df.standard_deviation_num))
dropmissing!(df)
@subset!(df, abs.(:z).<20)
df.z = Float64.(df.z)
histogram(df.z, normalize=:pdf, bins=100)

p = [.3,.3,.4]
Î¼ = 0.
Ï„ = [1.,2.,3.]
pFâ‚€ = .25
pLâ‚€ = .2
pUâ‚€ = .2
kL = 1.
kU = 1.
m = 3.

o = HnFstuff(df.z, D=length(Ï„), interpres=300, quadnodes=25)
@time res = optimize(negHnFllSharedÎ¼(o), vcat(SimplextoRâ¿(p),Î¼,log.(Ï„),logit(pFâ‚€),logit(pLâ‚€),logit(pUâ‚€),log(kL),log(kU),log(m)), LBFGS(), autodiff=:forward)
Î¸â‚‚ = Optim.minimizer(res)
pÌ‚, Î¼Ì‚ , Ï„Ì‚ , pÌ‚Fâ‚€, pÌ‚Lâ‚€, pÌ‚Uâ‚€, kÌ‚L, kÌ‚U, mÌ‚ = Râ¿toSimplex(Î¸â‚‚[1:o.D-1]), Î¸â‚‚[o.D], exp.(Î¸â‚‚[o.D+1:2*o.D]), logistic(Î¸â‚‚[2*o.D+1]), logistic(Î¸â‚‚[2*o.D+2]), logistic(Î¸â‚‚[2*o.D+3]), exp(Î¸â‚‚[2*o.D+4]), exp(Î¸â‚‚[2*o.D+5]), exp(Î¸â‚‚[2*o.D+6])
pÌ‚Dâ‚€ = 1 - pÌ‚Fâ‚€
println((pÌ‚=pÌ‚, Î¼Ì‚ =Î¼Ì‚ , Ï„Ì‚ =Ï„Ì‚ , pÌ‚Fâ‚€=pÌ‚Fâ‚€, pÌ‚Lâ‚€=pÌ‚Lâ‚€, pÌ‚Uâ‚€=pÌ‚Uâ‚€, kÌ‚L=kÌ‚L, kÌ‚U=kÌ‚U, mÌ‚=mÌ‚))
ses = sqrt.(diag(pinv(ForwardDiff.hessian(negHnFllSharedÎ¼(o), Î¸))))
zplot = -20:.1:20
pplot = map(z->HnFl(z; p=pÌ‚, Î¼=fill(Î¼Ì‚ ,o.D), Ï„=Ï„Ì‚ , pFâ‚€=pÌ‚Fâ‚€, pLâ‚€=pÌ‚Lâ‚€, pUâ‚€=pÌ‚Uâ‚€, kL=kÌ‚L, kU=kÌ‚U, m=mÌ‚), zplot)
plot!(zplot, pplot)
